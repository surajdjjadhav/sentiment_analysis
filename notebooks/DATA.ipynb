{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every great gangster movie has under-currents ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just saw this film last night, and I have to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is mildly entertaining if one neglec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quentin Tarantino's partner in crime Roger Ava...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I sat through this on TV hoping because of the...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>I was really disappointed by this movie. Great...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>This is a great example of a good, dumb movie....</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Do you know that they want to escavate the Moo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>I really wanted to like The Pillow Book. Intri...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Steve Biko was a black activist who tried to r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews sentiment\n",
       "0    Every great gangster movie has under-currents ...  positive\n",
       "1    I just saw this film last night, and I have to...  positive\n",
       "2    This film is mildly entertaining if one neglec...  negative\n",
       "3    Quentin Tarantino's partner in crime Roger Ava...  negative\n",
       "4    I sat through this on TV hoping because of the...  negative\n",
       "..                                                 ...       ...\n",
       "495  I was really disappointed by this movie. Great...  negative\n",
       "496  This is a great example of a good, dumb movie....  positive\n",
       "497  Do you know that they want to escavate the Moo...  negative\n",
       "498  I really wanted to like The Pillow Book. Intri...  negative\n",
       "499  Steve Biko was a black activist who tried to r...  positive\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\suraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\suraj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie current human drama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino partner crime roger avary co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time dear gussi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>really disappointed movie great actor potentia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>great example good dumb movie high art mean sc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>know want escavate moon real geneve debated pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>really wanted like pillow book intriguing stor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>steve biko black activist tried resist white m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  sentiment\n",
       "0    every great gangster movie current human drama...          1\n",
       "1    saw film last night say loved every minute tak...          1\n",
       "2    film mildly entertaining one neglect acknowled...          0\n",
       "3    quentin tarantino partner crime roger avary co...          0\n",
       "4    sat tv hoping name would worth time dear gussi...          0\n",
       "..                                                 ...        ...\n",
       "495  really disappointed movie great actor potentia...          0\n",
       "496  great example good dumb movie high art mean sc...          1\n",
       "497  know want escavate moon real geneve debated pr...          0\n",
       "498  really wanted like pillow book intriguing stor...          0\n",
       "499  steve biko black activist tried resist white m...          1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.constens import CONFIG\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.sparse\n",
    "import warnings\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "def remove_number(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "\n",
    "def remove_url(text):\n",
    "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    try:\n",
    "        return df[\"reviews\"].apply(lower)\\\n",
    "                            .apply(remove_punctuation)\\\n",
    "                            .apply(remove_stop_words)\\\n",
    "                            .apply(remove_number)\\\n",
    "                            .apply(lemmatization)\\\n",
    "                            .apply(remove_url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during normalization: {e}\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"reviews\"] = normalize_text(df)\n",
    "    df = df[df[\"sentiment\"].isin([\"positive\", \"negative\"])]\n",
    "    df['sentiment'] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "    return df\n",
    "\n",
    "df = load_data(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews      0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [reviews, sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "empty_rows = df['reviews'] == ''\n",
    "print(df[empty_rows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df[\"reviews\"].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aag' 'abandon' 'abandoned' ... 'zu' 'zuckers' 'étc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(df[\"reviews\"])\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    269\n",
      "1    231\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[2025-03-18 09:52:29,492] root - INFO - nltk libraries downloading done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-03-18 09:52:29,511] root - INFO - Data loading completed\n",
      "[2025-03-18 09:52:29,517] root - INFO - Text normalization initialized\n",
      "[2025-03-18 09:52:29,846] root - INFO - Text normalization completed\n",
      "[2025-03-18 09:52:29,846] root - INFO - Target column encoding completed\n"
     ]
    }
   ],
   "source": [
    "from src.constants import CONFIG\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dagshub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import re\n",
    "import string\n",
    "from src.logger import logging\n",
    "from src.Exception import MyException\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import scipy.sparse\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "logging.info(\"nltk libraries downloading done\")\n",
    "\n",
    "# try:\n",
    "#     mlflow.set_tracking_uri(CONFIG[\"mlflow_tracking_uri\"])\n",
    "#     dagshub.init(repo_owner=CONFIG[\"dagshub_repo_owner\"], repo_name=CONFIG[\"dagshub_repo_name\"], mlflow=True)\n",
    "\n",
    "#     mlflow.set_experiment(CONFIG[\"experiment_name\"])\n",
    "#     logging.info(\"MLflow and Dagshub initialized successfully.\")\n",
    "# except Exception as e:\n",
    "#     logging.error(f\"Error initializing MLflow and Dagshub: {e}\")\n",
    "#     raise MyException(f\"Initialization error: {e}\")\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    try:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "\n",
    "def remove_number(text):\n",
    "    try:\n",
    "        return re.sub(r'\\d+', '', text)\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "\n",
    "def lower(text):\n",
    "    try:\n",
    "        return text.lower()\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "    \n",
    "def lemmatization(text):\n",
    "    try:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return \" \".join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "    \n",
    "def remove_punctuation(text):\n",
    "    try:\n",
    "        return re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "\n",
    "def remove_url(text):\n",
    "    try:\n",
    "        return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "\n",
    "def normalize_text(df):\n",
    "    try:\n",
    "        logging.info(\"Text normalization initialized\")\n",
    "        df[\"reviews\"] = df[\"reviews\"].apply(lambda x: lower(x))\\\n",
    "                                    .apply(lambda x: remove_punctuation(x))\\\n",
    "                                    .apply(lambda x: remove_stop_words(x))\\\n",
    "                                    .apply(lambda x: remove_number(x))\\\n",
    "                                    .apply(lambda x: lemmatization(x))\\\n",
    "                                    .apply(lambda x: remove_url(x))\n",
    "        logging.info(\"Text normalization completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        logging.info(\"Data loading completed\")\n",
    "\n",
    "        df = normalize_text(df)\n",
    "\n",
    "        df = df[df[\"sentiment\"].isin([\"positive\", \"negative\"])]\n",
    "        df['sentiment'] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "        logging.info(\"Target column encoding completed\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise MyException(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "df = load_data(\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    269\n",
       "1    231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"].isin([\"positive\", \"negative\"])]\n",
    "df['sentiment'] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every great gangster movie has under-currents ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just saw this film last night, and I have to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is mildly entertaining if one neglec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quentin Tarantino's partner in crime Roger Ava...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I sat through this on TV hoping because of the...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews sentiment\n",
       "0  Every great gangster movie has under-currents ...  positive\n",
       "1  I just saw this film last night, and I have to...  positive\n",
       "2  This film is mildly entertaining if one neglec...  negative\n",
       "3  Quentin Tarantino's partner in crime Roger Ava...  negative\n",
       "4  I sat through this on TV hoping because of the...  negative"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"].isin([\"positive\", \"negative\"])]\n",
    "\n",
    "df['sentiment'] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every great gangster movie has under-currents ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just saw this film last night, and I have to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is mildly entertaining if one neglec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quentin Tarantino's partner in crime Roger Ava...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I sat through this on TV hoping because of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>I was really disappointed by this movie. Great...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>This is a great example of a good, dumb movie....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Do you know that they want to escavate the Moo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>I really wanted to like The Pillow Book. Intri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Steve Biko was a black activist who tried to r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  sentiment\n",
       "0    Every great gangster movie has under-currents ...          1\n",
       "1    I just saw this film last night, and I have to...          1\n",
       "2    This film is mildly entertaining if one neglec...          0\n",
       "3    Quentin Tarantino's partner in crime Roger Ava...          0\n",
       "4    I sat through this on TV hoping because of the...          0\n",
       "..                                                 ...        ...\n",
       "495  I was really disappointed by this movie. Great...          0\n",
       "496  This is a great example of a good, dumb movie....          1\n",
       "497  Do you know that they want to escavate the Moo...          0\n",
       "498  I really wanted to like The Pillow Book. Intri...          0\n",
       "499  Steve Biko was a black activist who tried to r...          1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
